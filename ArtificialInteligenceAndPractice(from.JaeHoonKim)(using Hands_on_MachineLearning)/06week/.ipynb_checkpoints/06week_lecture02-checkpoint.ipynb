{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c480b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "#######\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "#######\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "MNIST_PATH = PROJECT_ROOT_DIR + \"/datasets/mnist/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c7984c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setosa_or_versicolor(iris):\n",
    "    X = iris[\"data\"]  # petal length, petal width\n",
    "    y = iris[\"target\"]\n",
    "\n",
    "    setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "    print(setosa_or_versicolor)\n",
    "    return X[setosa_or_versicolor], y[setosa_or_versicolor]\n",
    "\n",
    "def performance(y_test, y_test_pred, average='binary'):\n",
    "    precision = precision_score(y_test, y_test_pred, average=average)\n",
    "    recall = recall_score(y_test, y_test_pred, average=average)\n",
    "    f1 = f1_score(y_test, y_test_pred, average=average)\n",
    "    return precision, recall, f1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0026ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Large margin classification\n",
    "    iris = datasets.load_iris()\n",
    "    \n",
    "    # make training data for binary classifiers\n",
    "    X, y = get_setosa_or_versicolor(iris)\n",
    "#     print(len(X))\n",
    "#     print(X)\n",
    "#     print(y)\n",
    "    \n",
    "    param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], \n",
    "     'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], \n",
    "     'n_estimators': [3, 10], \n",
    "     'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "    forest_reg = RandomForestRegressor(random_state=42)\n",
    "#     svm_clf3 = Pipeline([\n",
    "#        (\"scaler\", MinMaxScaler()),\n",
    "#        (\"linear_svc\", LinearSVC(C=0.1, loss=\"hinge\", random_state=42)),\n",
    "#     ])\n",
    "\n",
    "#     pipeline\n",
    "    grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           return_train_score=True)\n",
    "#     forest_reg = RandomForestRegressor(random_state=42)\n",
    "#     grid_search = \n",
    "                           \n",
    "                           \n",
    "    grid_search.fit(X, y)\n",
    "    y_pred = grid_search.predict(X)\n",
    "    precision, recall, f1 = performance(y, y_pred, average=\"micro\")\n",
    "    print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64259cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# try 12 (3×4) combinations of hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m]},\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# then try 6 (2×3) combinations with bootstrap set as False\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mFalse\u001b[39;00m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]},\n\u001b[0;32m      8\u001b[0m   ]\n\u001b[1;32m---> 10\u001b[0m forest_reg \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestRegressor\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \u001b[39;00m\n\u001b[0;32m     12\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(forest_reg, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     13\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                            return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# param_grid = [\n",
    "#     # try 12 (3×4) combinations of hyperparameters\n",
    "#     {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "#     # then try 6 (2×3) combinations with bootstrap set as False\n",
    "#     {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "#   ]\n",
    "\n",
    "# forest_reg = RandomForestRegressor(random_state=42)\n",
    "# # train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "# grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "#                            scoring='neg_mean_squared_error',\n",
    "#                            return_train_score=True)\n",
    "# grid_search.fit(housing_prepared, housing_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
